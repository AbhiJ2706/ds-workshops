{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2UAcsWi5ECR3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def printline(n):\n",
        "    print()\n",
        "    print(f\"{n} -------------------------------\")\n",
        "    print()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8YuFhl5UEIs3"
      },
      "source": [
        "# Numpy\n",
        "\n",
        "### Introduction\n",
        "\n",
        "Numpy, short for Numerical Python, serves 1 quintessential purpose for data science applications- it provides fast, efficient n-dimensional arrays implemented in C, with support for many essential operations on these arrays.\n",
        "\n",
        "Regular python arrays are quite good, but they aren't as efficient as they could be and that could negatively affect performance, especially for large applications. The efficiency gains of numpy arrays are not immediately visible with a small array, but they are much more efficient for large and multidimensional arrays.\n",
        "\n",
        "### Basic Numpy Constructs\n",
        "\n",
        "Numpy offers a single basic data structure- ```np.array```.\n",
        "it is written in C and provides many memory optimizations which make it miles more efficient than a python array.\n",
        "\n",
        "Most importantly, numpy arrays are stored contiguously in memory- that is, there are no gaps in the memory storage, you could access adjacent entries in the computer's memory and see the items side by side. An n-dimensional index (e.g., ```x[1][2][3]``` gives the address ```[address of x] + (1 + 2 + 3) * sizeof(int)```). This makes them easily copyable and easy to operate on. \n",
        "\n",
        "There are other numpy data structures such as ```np.matrix``` but ```np.ndarray``` will be most of what you see.\n",
        "\n",
        "All the numpy operations in this tutorial are specifically for dealing with numpy arrays. Numpy arrays will now be referenced as ndarrays or just arrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FiVBAUhyEQuZ"
      },
      "outputs": [],
      "source": [
        "# python array- slow and inefficient for large arrays\n",
        "x = [[1, 2, 3], [1, 2, 3]]\n",
        "printline(1)\n",
        "print(x)\n",
        "print(type(x))\n",
        "\n",
        "# numpy array- fast, efficient for all sizes of arrays\n",
        "# note on dtype- it is int32 by default, but you should ALWAYS ALWAYS specify\n",
        "x = np.array([[1, 2, 3], [1, 2, 3]], dtype=np.int32)\n",
        "printline(2)\n",
        "print(x)\n",
        "print(type(x))\n",
        "\n",
        "# numpy provides lots more support for multidimensional arrays (these work for\n",
        "# single dimensional arrays too)\n",
        "print(x.shape)\n",
        "print(x.dtype)\n",
        "print(x.ndim)\n",
        "\n",
        "# indexing syntax\n",
        "print(x[0, 0])\n",
        "print(x[0][0])\n",
        "\n",
        "# note: the subarrays are also numpy objects now!\n",
        "print(x[0])\n",
        "print(type(x[0]))\n",
        "\n",
        "# some conventional python constructs work with ndarrays:\n",
        "print(len(x))\n",
        "for item in x:\n",
        "    print(item)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HJqvpfWEJJNV"
      },
      "source": [
        "### Essential Fields\n",
        "\n",
        "There are a couple of essential ndarray fields:\n",
        "\n",
        "- `dtype`: type of the object the ndarray contains. dtype can be any of the following:\n",
        "    - predefined type from the numpy library\n",
        "    - predefined native python type\n",
        "    - custom type defined by the user (e.g., user-defined class)\n",
        "\n",
        "  These types are strictly enforced, unlike normal python arrays.\n",
        "- `ndim`: the number of dimensions of the ndarray, will always be at least 1.\n",
        "- `shape`: the actual dimensions of the ndarray. Stored as tuple within the ndarray object. The order of the dimensions is extremely important- they are evaluated in terms of array nesting.\n",
        "\n",
        "__A note on the syntax of shape:__ when printing 1-dimensional shape (or when interacting with numpy using other libraries such as tensorflow), you may see output like this: (3,). The weird part is the comma after the 3- it's a 1-item tuple so there's no business having a comma there. The comma doesn't actually mean anything."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ijVeDVyJJVa"
      },
      "outputs": [],
      "source": [
        "x = np.array([1, 2, 3], dtype=np.int16)\n",
        "printline(1)\n",
        "print(x.shape)\n",
        "\n",
        "x = np.array(\n",
        "    [[1.5, 2.3, 3.4],\n",
        "     [4.5, 5.6, 6.7]], dtype=np.float64)\n",
        "printline(2)\n",
        "print(x.shape)\n",
        "\n",
        "x = np.array(\n",
        "    [[[x ** y for x in range(1, 3)] for y in range(1, 3)],\n",
        "     [[x ** y for x in range(1, 3)] for y in range(3, 5)],\n",
        "     [[x ** y for x in range(1, 3)] for y in range(5, 7)]], dtype=np.double)\n",
        "printline(3)\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9CJbRjYKtBz"
      },
      "outputs": [],
      "source": [
        "# quiz: what's the shape of the following arrays?\n",
        "x = np.array(\n",
        "    [[1, 2],\n",
        "     [1, 2],\n",
        "     [1, 2]])\n",
        "\n",
        "y = np.array([[[1], [1], [1], [1]],\n",
        "              [[1], [1], [1], [1]],\n",
        "              [[1], [1], [1], [1]],\n",
        "              [[1], [1], [1], [1]]])\n",
        "\n",
        "z = np.array(\n",
        "    [[[[1, 2, 3], [4, 5, 6]],\n",
        "      [[7, 8, 9], [10, 11, 12]],\n",
        "      [[1, 2, 3], [4, 5, 6]],\n",
        "      [[7, 8, 9], [10, 11, 12]],\n",
        "      [[1, 2, 3], [4, 5, 6]],\n",
        "      [[7, 8, 9], [10, 11, 12]]]])\n",
        "\n",
        "print(x.shape, y.shape, z.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WYXovENkPXqi"
      },
      "source": [
        "### Reshape operation\n",
        "\n",
        "Reshape allows you to change the shape of any array. You have to be a bit careful when using it though- the new shape could rearrange elements in potentially unintended ways!\n",
        "\n",
        "There is only 1 rule to remember when using shape: __the product of the new dimensions must be exactly the total number of array items.__ Here items refers to the total number of non-array objects in the array.\n",
        "\n",
        "### Special case- reshaping with -1\n",
        "\n",
        "it is possible to enter a single reshaping dimension with -1. This is assumed to be an unknown dimension that numpy infers for you. A little less work to do :)\n",
        "\n",
        "This is also the *one and only* exception to the rule above- you'll see that the ouputted dimensions for a reshape operation with -1 to follow this rule!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlduCF2IKto0"
      },
      "outputs": [],
      "source": [
        "x = np.array(\n",
        "    [[1, 2],\n",
        "     [1, 2],\n",
        "     [1, 2]])\n",
        "\n",
        "# total number of elements remains equal\n",
        "printline(1)\n",
        "print(x.reshape(2, 3))\n",
        "print(x.reshape(1, 6))\n",
        "print(x.reshape(6, 1))\n",
        "\n",
        "z = np.array(\n",
        "    [[[[1, 2, 3], [4, 5, 6]],\n",
        "      [[7, 8, 9], [10, 11, 12]],\n",
        "      [[1, 2, 3], [4, 5, 6]],\n",
        "      [[7, 8, 9], [10, 11, 12]],\n",
        "      [[1, 2, 3], [4, 5, 6]],\n",
        "      [[7, 8, 9], [10, 11, 12]]]])\n",
        "\n",
        "printline(2)\n",
        "# dimensionality reduction\n",
        "print(z.reshape(6, 6))\n",
        "# dimensionality increase\n",
        "print(z.reshape(2, 3, 2, 3, 1))\n",
        "# using -1\n",
        "print(z.reshape(3, -1, 6))\n",
        "print(z.reshape(3, -1, 6).shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "IUGyuiIeNMGK"
      },
      "source": [
        "### Various operations\n",
        "\n",
        "Numpy provides various operations which can be applied to arrays:\n",
        "\n",
        "* `filter (via condition in the [] operator)`\n",
        "* `order`\n",
        "* `sum`\n",
        "* `max`\n",
        "* `mask (via a conditional expression)`\n",
        "* `transpose`\n",
        "* `sort (note: happens in-place)`\n",
        "* `any`\n",
        "* `all`\n",
        "* `concat`\n",
        "\n",
        "These are all properties of the `np.ndarray` object (except `concat`).\n",
        "\n",
        "See the documentation to see which are part of the array structure and which are not: https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html\n",
        "\n",
        "### Overloading default operations\n",
        "\n",
        "Ndarrays can also use some default operations, such as `+`, `-`, etc. These have mathematical behaviour though- `+` will take the vector sum of the arrays, and `-` and such act accordingly.\n",
        "\n",
        "### Behaviour with dtypes\n",
        "\n",
        "The above operations can work on arrays with different dtypes provided they are compatible. The dtype of the result is chosen automatically to facilitate all items of the result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRRtmPbSLD5G"
      },
      "outputs": [],
      "source": [
        "z = np.array(\n",
        "    [[[[1, 2, 3], [4, 5, 6]],\n",
        "      [[7, 8, 9], [10, 11, 12]],\n",
        "      [[13, 14, 15], [16, 17, 18]],\n",
        "      [[19, 20, 21], [22, 23, 24]],\n",
        "      [[25, 26, 27], [28, 29, 30]],\n",
        "      [[31, 32, 33], [34, 35, 36]]]], dtype=np.int64)\n",
        "print(z.shape)\n",
        "\n",
        "# filter\n",
        "printline(1)\n",
        "print(z[z % 6 == 0])\n",
        "\n",
        "# sum\n",
        "printline(2)\n",
        "print(z.sum())\n",
        "\n",
        "# max\n",
        "printline(3)\n",
        "print(z.max())\n",
        "\n",
        "# mask\n",
        "printline(4)\n",
        "print(z % 3 == 0)\n",
        "\n",
        "# transpose\n",
        "printline(5)\n",
        "print(z.transpose())\n",
        "print(z.reshape(6, 6).transpose())\n",
        "# notice how the shape changes for transpose- it's inverted\n",
        "print(z.transpose().shape)\n",
        "\n",
        "# sort\n",
        "printline(6)\n",
        "z.sort()\n",
        "print(z)\n",
        "\n",
        "# any/all\n",
        "printline(7)\n",
        "print((z % 3 == 0).any())\n",
        "print((z % 3 == 0).all())\n",
        "\n",
        "# concat\n",
        "printline(8)\n",
        "a = np.array(\n",
        "    [[[[1, 2, 3], [4, 5, 6]],\n",
        "      [[7, 8, 9], [10, 11, 12]],\n",
        "      [[13, 14, 15], [16, 17, 18]],\n",
        "      [[19, 20, 21], [22, 23, 24]],\n",
        "      [[25, 26, 27], [28, 29, 30]],\n",
        "      [[31, 32, 33], [34, 35, 36]]]], dtype=np.int64)\n",
        "\n",
        "# notes\n",
        "# - arrays must be passed on as a tuple\n",
        "# - arrays must have same shape\n",
        "print(np.concatenate((z, a)))\n",
        "\n",
        "# infix operations\n",
        "printline(9)\n",
        "print(z + a)\n",
        "print(z - a)\n",
        "print(z * a)\n",
        "print(z / a)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XOnUG797LIqi"
      },
      "source": [
        "### Array axes\n",
        "\n",
        "Arrays can also be configured via their axis properties. Recall the output of an example shape command:\n",
        "\n",
        "```\n",
        ">>> z = np.array(\n",
        "    [[[[1, 2, 3], [4, 5, 6]],\n",
        "      [[7, 8, 9], [10, 11, 12]],\n",
        "      [[1, 2, 3], [4, 5, 6]],\n",
        "      [[7, 8, 9], [10, 11, 12]],\n",
        "      [[1, 2, 3], [4, 5, 6]],\n",
        "      [[7, 8, 9], [10, 11, 12]]]])\n",
        "\n",
        ">>> print(z.shape) \n",
        "(1, 6, 2, 3)\n",
        "```\n",
        "\n",
        "Here, we see the array has 4 dimensions. In Numpy, these dimensions are 0-indexed- that is, the size of axis 0 is 1, the size of axis 1 is 6, and so on. Numpy operations can be applied on certain axes or all axes, using the ```axis``` default parameter.\n",
        "\n",
        "### Operation behaviour with axes\n",
        "\n",
        "Numpy operations can be applied to some or all axes. This may cuase the operation to flatten or alter the shape of the array to facilitate the operation. Additionally, you may end up with an array in response to an operation that you may expect to provide you with a number.\n",
        "\n",
        "Some operations may broadcast the operation across all axes, giving a return array with a completely new shape. This includes adding arrays with `+`. This only applies in certain situation though- in other you may get an error.\n",
        "\n",
        "The rule for computing the new shape is as follows: \n",
        "\n",
        "if we have 2 arrays `a` and `b`, where `a` has shape `(a1, a2, ..., an)` and `b` has shape `(b1, b2, ..., bn)`, and the result of `a [] b` is `c` with `(c1, c2, ..., cn)`:\n",
        "\n",
        "for each `i` in `1` to `n`:\n",
        "\n",
        "- if `ai` == `bi`, then `ci` = `ai` = `bi`.\n",
        "- if `ai` == 1 != `bi` then `ci` = `bi`.\n",
        "- if `bi` == 1 != `ai` then `ci` = `ai`.\n",
        "- if `ai` != 1 != `bi` then `error`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiCqmDOvMG_A"
      },
      "outputs": [],
      "source": [
        "z = np.array(\n",
        "    [[[[19, 20, 21], [22, 23, 24]],\n",
        "      [[25, 26, 27], [28, 29, 30]],\n",
        "      [[13, 14, 15], [16, 17, 18]],\n",
        "      [[31, 32, 33], [34, 35, 36]],\n",
        "      [[1, 2, 3], [4, 5, 6]],\n",
        "      [[7, 8, 9], [10, 11, 12]]]], dtype=np.int64)\n",
        "print(z.shape)\n",
        "\n",
        "# filter\n",
        "printline(1)\n",
        "print(z[z % 6 == 0])\n",
        "\n",
        "# sum\n",
        "printline(2)\n",
        "print(z.sum())\n",
        "print(z.sum(axis=1))\n",
        "\n",
        "# max\n",
        "printline(3)\n",
        "print(z.max())\n",
        "print(z.max(axis=2))\n",
        "\n",
        "# mask\n",
        "printline(4)\n",
        "print((z % 3 == 0).any(axis=1))\n",
        "\n",
        "# sort\n",
        "printline(6)\n",
        "z.sort()\n",
        "print(z)\n",
        "z.sort(axis=1)\n",
        "print(z)\n",
        "z.sort(axis=2)\n",
        "print(z)\n",
        "\n",
        "# any/all\n",
        "printline(7)\n",
        "print((z % 3 == 0).any(axis=3))\n",
        "print((z % 3 == 0).all(axis=2))\n",
        "\n",
        "# concat\n",
        "printline(8)\n",
        "a = np.array(\n",
        "    [[[[7, 8, 9], [10, 11, 12]]],\n",
        "     [[[1, 2, 3], [4, 5, 6]]]], dtype=np.int64)\n",
        "print(a.shape)\n",
        "\n",
        "# infix operations\n",
        "printline(9)\n",
        "print(z + a)\n",
        "print(z - a)\n",
        "print(z * a)\n",
        "print(z / a)\n",
        "\n",
        "print((z + a).shape)\n",
        "print((z - a).shape)\n",
        "print((z * a).shape)\n",
        "print((z / a).shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ryeeb9n9LJ0f"
      },
      "source": [
        "### Generative functions\n",
        "\n",
        "Numpy also offers some operations for generation of arrays:\n",
        "\n",
        "* `linspace`\n",
        "* `arange`\n",
        "* `rng`\n",
        "\n",
        "These arrays can be reshaped as desired to become useful, and manipulated exactly the same as regular arrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJjbNiUqLKp4"
      },
      "outputs": [],
      "source": [
        "printline(1)\n",
        "print(np.arange(32))\n",
        "\n",
        "printline(2)\n",
        "print(np.linspace(5, 50, 24, dtype=int))\n",
        "\n",
        "printline(3)\n",
        "from numpy.random import default_rng\n",
        "\n",
        "rng = default_rng()\n",
        "values = rng.standard_normal(10000)\n",
        "\n",
        "print(values[:100])\n",
        "print(values[:100].reshape(10, 10))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oB_elNYUNk7d"
      },
      "source": [
        "# Pandas\n",
        "\n",
        "### Introduction\n",
        "\n",
        "Pandas also provides you with a single core data structure- the dataframe. If the `np.array` is analogous to a python list, then `pd.DataFrame` is (sort of) analogous to a python dictionary. \n",
        "\n",
        "Pandas is also built for scalability, but specifically for 2-dimensional data. You can think of a pandas dataframe like an SQL table, as they come complete with index numbers and column names!\n",
        "\n",
        "### Basic constructs\n",
        "\n",
        "There is only 1 we care about- the dataframe, i.e. `pd.DataFrame`. Dataframe act like SQL tables- their individual rows are identified by indices, and their columns by column names. Records can be individually picked out or filtered by row and column.\n",
        "\n",
        "### Copy attribute\n",
        "\n",
        "The `copy` attribute of dataframe creation is very important- it specifies if the dataframe is created on a copy or a reference to the source item. Copy is set to `True` by default. If it is set to `False`, then any changes to the source item will be progagated to the dataframe. Any changes to the dataframe will be propagated to the source object. *Note: this can only be specified when using a numpy array as input.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxA_8QDPX427"
      },
      "outputs": [],
      "source": [
        "# dataframe creation- several ways of creating the same dataframe\n",
        "\n",
        "# note: the items beings lists is important\n",
        "a = {\"a\": [1], \"b\": [2], \"c\": [3]}\n",
        "x = pd.DataFrame(a)\n",
        "\n",
        "a2 = ([\"a\", \"b\", \"c\"], [[1, 2, 3]])\n",
        "y = pd.DataFrame(a2[1], columns=a2[0])\n",
        "\n",
        "# pandas numpy integration\n",
        "a3 = np.array([[1, 2, 3]], dtype=np.int32)\n",
        "z = pd.DataFrame(a3, columns=[\"a\", \"b\", \"c\"], index=[0])\n",
        "\n",
        "printline(1)\n",
        "print(x)\n",
        "printline(2)\n",
        "print(y)\n",
        "printline(3)\n",
        "print(z)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zo3KJgWbnGsX"
      },
      "source": [
        "### Dataframe creation and shape/axis\n",
        "\n",
        "Dataframe creation is 1 crucial application of shape- pandas will form the database based on the shape *implied* by your combination of data, columns, and indices. This is not the same as the actual shape.\n",
        "\n",
        "Take the second dataframe above. If we used `[1, 2, 3]` instead of `[[1, 2, 3]]`, we actually would have gotten an error. This is because pandas wants min. 2d data- the shape of `[1, 2, 3]` is `(3,)` which is 1d. The shape *implied* by entering `[1, 2, 3]` as the data is `(3, 1)` (3 rows and 1 columns) since 3 items are provided on the 0th axis. The shape implied by entering `[[1, 2, 3]]` as the data is `(1, 3)` since we have 3 items on the 1st axis. \n",
        "\n",
        "The formula for the implied shape is `(length of indices, length of columns)` which is in fact `(size of axis 0, sise of axis 1)` of your data, unless you specify the columns and/or index parameters.\n",
        "\n",
        "You may need to pad arrays accordingly before turning them into dataframes."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jv5CoWtoX5Bq"
      },
      "source": [
        "### Parts of a dataframe\n",
        "\n",
        "There are several key parts of a dataframe:\n",
        "\n",
        "- `index`: row identifiers\n",
        "- `columns`: column identifiers\n",
        "- `ndim`: number of dataframe dimensions (should always be 2)\n",
        "- `size`: number of entries\n",
        "- `shape`: shape of the data\n",
        "- `values`: the actual values in the dataset\n",
        "- `axes`: analogous to numpy axes\n",
        "\n",
        "These variables are all either gettable, settable or both- when getting them, however, they may be wrapped in pandas objects. Only index and columns can be set. Rows and column values can be edited, but values itself cannot be set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fP2X9A3kaeHu"
      },
      "outputs": [],
      "source": [
        "# show gettable and settable\n",
        "\n",
        "a = np.array([[1, 2, 3], [6, 5, 4], [7, 8, 9], [12, 11, 10]], dtype=np.int32)\n",
        "z = pd.DataFrame(a, columns=[\"a\", \"b\", \"c\"], index=[\"a\", \"b\", \"c\", \"d\"])\n",
        "\n",
        "print(z)\n",
        "print(z.index)\n",
        "print(z.columns)\n",
        "print(z.values)\n",
        "print(z.ndim)\n",
        "print(z.size)\n",
        "print(z.shape)\n",
        "print(z.axes)\n",
        "\n",
        "# notable types:\n",
        "print(type(z.index))\n",
        "print(type(z.columns))\n",
        "print(type(z.values))\n",
        "\n",
        "z.index = [\"z\", \"y\", \"x\", \"w\"]\n",
        "z.columns = [\"pandas\", \"is\", \"cool\"]\n",
        "\n",
        "print(z)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "D7dRtDexrl4U"
      },
      "source": [
        "### Getting/Setting Values\n",
        "\n",
        "Getting and setting the actual values can be done in several ways. The most common is to simply dereference using the [] brackets. This allows us to do simple lookups, such as a row, or a column, or a single item.\n",
        "\n",
        "For more complex lookups, such as several rows and a single column, we need to use the special functions loc and iloc.\n",
        "- `loc`: gets the value based on the index and column provided.\n",
        "- `iloc`: gets the value based on the integer index and column provided (0-indexed)\n",
        "\n",
        "Both these can be used to get entire rows and columns as well. They are also compatible with python list syntax as well, such as slicing.\n",
        "\n",
        "### Series object\n",
        "\n",
        "Dataframe rows and columns are not stored as ndarrays- rather, they are stored as `pd.Series` types. These internally contain ndarrays containing the items, but the series wrapper allows for some more pandas-specific functionality. For instance, pandas series can have an index. Some attributes of pandas series:\n",
        "\n",
        "- `index`: same as DataFrame index\n",
        "- `data`: values\n",
        "- `dtype`: analogous to numpy dtype\n",
        "    - `dtype` can have a special value called object- this refers to any non-standard type, e.g. a user-defined class.\n",
        "- `copy`: same as DataFrame copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wk7JbC_lrmR3"
      },
      "outputs": [],
      "source": [
        "a = np.array([[1, 2, 3], [6, 5, 4], [7, 8, 9], [12, 11, 10]], dtype=np.int32)\n",
        "z = pd.DataFrame(a, columns=[\"a\", \"b\", \"c\"], index=[\"a\", \"b\", \"c\", \"d\"])\n",
        "print(z)\n",
        "\n",
        "# location is presented as (index(es), column(s))\n",
        "\n",
        "printline(1)\n",
        "z.loc[\"a\", \"a\"] = 100\n",
        "print(z)\n",
        "\n",
        "z.iloc[0, 1] = 200\n",
        "print(z)\n",
        "\n",
        "print(z[\"a\"])\n",
        "print(z[[\"b\"]])\n",
        "print(z[[\"b\", \"c\"]])\n",
        "try:\n",
        "    print(z[\"a\", [\"b\", \"c\"]])\n",
        "except Exception as e:\n",
        "    print(type(e), e)\n",
        "\n",
        "printline(2)\n",
        "# get row\n",
        "print(z.loc[\"a\"])\n",
        "print(type(z.loc[\"a\"]))\n",
        "# get column\n",
        "print(z.loc[:, \"a\"])\n",
        "print(type(z.loc[:, \"a\"]))\n",
        "\n",
        "printline(3)\n",
        "# notice the subtle change in syntax here- it makes a major difference!\n",
        "# get rows\n",
        "print(z.loc[[\"a\", \"b\"]])\n",
        "print(type(z.loc[[\"a\", \"b\"]]))\n",
        "# get columns\n",
        "print(z.loc[:, [\"a\", \"b\"]])\n",
        "print(type(z.loc[:, [\"a\", \"b\"]]))\n",
        "# get specific columns and rows\n",
        "print(z.loc[[\"c\"], [\"a\", \"b\"]])\n",
        "print(type(z.loc[[\"c\"], [\"a\", \"b\"]]))\n",
        "# set specific columns and rows\n",
        "z.loc[[\"c\"], [\"a\", \"b\"]] = [300, 400]\n",
        "print(z)\n",
        "z.iloc[[3], [0, 2]] = [500, 600]\n",
        "print(z)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PLUgyzG2nLLs"
      },
      "source": [
        "### What can you put in a dataframe?\n",
        "\n",
        "Just about anything (including other dataframes)!\n",
        "\n",
        "Values can be inserted individually, so in this sense, a dataframe behaves like a dictionary. For example, you can say `z.loc[\"d\", \"e\"] = 4` if `z` has no row `\"d\"` or column `\"e\"`. Values can also be inserted as rows or columns.\n",
        "\n",
        "### A note on append\n",
        "\n",
        "Pandas was recently updated to version 2.0. In 1.x, there was a method called append which made it very easy to add rows to your dataframe. This method *no longer works*. Many stackoverflow threads will tell you to use it. **You cannot.** Try the methods below instead!\n",
        "\n",
        "### A note on series\n",
        "\n",
        "Let's say we try to insert a series into a dataframe. In this case, *only* the items corresponding to an index equivalent to a column or index name will be added to the dataframe. The series does *not* have to be the size of a row/column of the dataframe. If the index is not specified, the row/column will be created but none of the items will be added.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7k6ccvCrg1b"
      },
      "outputs": [],
      "source": [
        "a = np.array([[1, 2, 3], [6, 5, 4], [7, 8, 9], [12, 11, 10]], dtype=np.int32)\n",
        "z = pd.DataFrame(a, columns=[\"a\", \"b\", \"c\"], index=[\"a\", \"b\", \"c\", \"d\"])\n",
        "print(z)\n",
        "\n",
        "printline(1)\n",
        "z.loc[\"d\", \"e\"] = 5\n",
        "print(z)\n",
        "\n",
        "z.loc[\"f\", :] = [13, 14, 15, 16]\n",
        "print(z)\n",
        "\n",
        "printline(2)\n",
        "b = pd.Series(np.array([17, 18, 19, 20], dtype=np.int32), index=[\"w\", \"x\", \"y\", \"z\"])\n",
        "z.loc[\"g\", :] = b\n",
        "print(z)\n",
        "\n",
        "b = pd.Series(np.array([17, 18, 19, 20, 21, 22, 23, 24], dtype=np.int32), \n",
        "              index=[\"w\", \"a\", \"x\", \"b\", \"y\", \"c\", \"z\", \"e\"])\n",
        "z.loc[\"g\", :] = b\n",
        "print(z)\n",
        "\n",
        "# no effect\n",
        "b = pd.Series(np.array([25, 26, 27, 28], dtype=np.int32))\n",
        "z.loc[\"g\", :] = b\n",
        "print(z)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "24VT3dWp43NX"
      },
      "source": [
        "### Copy semantics\n",
        "\n",
        "*Recall: copy can only be specified when using a numpy array as input.*\n",
        "\n",
        "If a dataframe has copy set to `True`, but a series-turned-row of the dataframe has copy set to `False`, which takes precedence?\n",
        "\n",
        "The dataframe's copy settings always take precedence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDVXASmu-o7j"
      },
      "outputs": [],
      "source": [
        "printline(1)\n",
        "a = np.array([7, 8, 9])\n",
        "b = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "\n",
        "z = pd.DataFrame(b, copy=True)\n",
        "print(z)\n",
        "\n",
        "a = pd.Series(a, copy=False)\n",
        "z.loc[0] = a\n",
        "print(z)\n",
        "\n",
        "a[1] = 100\n",
        "print(z)\n",
        "\n",
        "printline(2)\n",
        "a = np.array([7, 8, 9])\n",
        "b = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "\n",
        "z = pd.DataFrame(b, copy=False)\n",
        "print(z)\n",
        "\n",
        "a = pd.Series(a, copy=True)\n",
        "z.loc[0] = a\n",
        "print(z)\n",
        "\n",
        "b[1][1] = 100\n",
        "print(z)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-Oo9D4kavzn2"
      },
      "source": [
        "### Operations on dataframes\n",
        "\n",
        "There are many operations that can be applied to a dataframe. By default, they are applied to the whole column or row specified (though you can't specify a row for all of these). Here are some essential operations:\n",
        "\n",
        "- `astype` [row]: changes the dtype of a row\n",
        "- `sort_values` [row, column]: sort rows by column(s) specified or columns by row(s) specified.\n",
        "- `filter` [row, column]: filters rows and columns, via bitwise syntax, e.g. & | ~. The method `filter` does not exist in dataframes, it is done in square brackets [].\n",
        "- statistics \n",
        "    - `describe`: gives full insights into the data\n",
        "    - `mean` \n",
        "    - `std`\n",
        "- `iterrows`: allows iteration over rows\n",
        "- `items`: allows iteration over columns\n",
        "- `apply`: applies a specified function to all columns or rows, cannot remove/add rows in this way.\n",
        "\n",
        "### Common error with filter\n",
        "\n",
        "`ValueError: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().`\n",
        "\n",
        "This error occurs if you don't put brackets around every condition within your expression. A condition is an expression of the form `(dataframe[row/column select] (condition) (value))`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUdkk0mQvzum"
      },
      "outputs": [],
      "source": [
        "a = np.array([[1, 2, 3], [7, 8, 9], [6, 5, 4], [12, 11, 10]], dtype=np.int32)\n",
        "z = pd.DataFrame(a, columns=[\"a\", \"b\", \"c\"], index=[\"a\", \"b\", \"c\", \"d\"])\n",
        "print(z)\n",
        "\n",
        "printline(1)\n",
        "z.loc[:, \"a\"] = z.loc[:, \"a\"].astype(np.float64)\n",
        "print(z)\n",
        "print(z.dtypes)\n",
        "\n",
        "printline(2)\n",
        "z = z.sort_values((\"a\"))\n",
        "print(z)\n",
        "\n",
        "printline(3)\n",
        "print(z[z[\"a\"] == 1])\n",
        "# when applying filtering over both rows and columns- values are not removed\n",
        "print(z[(z[\"a\"] != 1) & (z[[\"b\"]] > 5)])\n",
        "# notice the brackets around EVERY SINGLE part of the expression!\n",
        "print(z[((z[\"b\"] >= 8) & (z[\"b\"] <= 12)) | ~(z[[\"c\"]] % 2 == 0)])\n",
        "\n",
        "printline(4)\n",
        "z.describe()\n",
        "\n",
        "printline(5)\n",
        "for index, row in z.iterrows():\n",
        "    print(index)\n",
        "    print(row)\n",
        "\n",
        "printline(6)\n",
        "for label, column in z.items():\n",
        "    print(label)\n",
        "    print(column)\n",
        "\n",
        "printline(7)\n",
        "print(z.apply(lambda x: x * 2))\n",
        "print(z.apply(np.sum, axis=0))\n",
        "print(z.apply(np.sum, axis=1))\n",
        "\n",
        "printline(8)\n",
        "def test_fn(x):\n",
        "    print(type(x))\n",
        "    print(x)\n",
        "    return x[x >= 5]\n",
        "    #print(x)\n",
        "\n",
        "print(z.apply(test_fn, axis=0))\n",
        "print(z.apply(test_fn, axis=1))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3nG1UBQaxkG7"
      },
      "source": [
        "### Missing values\n",
        "\n",
        "Pandas has built in support for missing values. This is critical when importing dataset that don't contain all their values. Numpy has a special object, comparable to Python's `None`, called `np.nan` (short for Not a Number), used widely in Pandas. When printing a dataframe, it shows up as `NaN`. There are several methods which help support this:\n",
        "\n",
        "- `isnan`: determines if an entry is nan\n",
        "- `fillna`: fills all NaNs with the specified value(s). You can specify a single value, a dictionary, a series, or a dataframe to fill the values. When not specifying a single value, values are filled in according to index (if dictionary or series) and columns (if dataframe).\n",
        "- `dropna`: drops all rows/columns with at least 1 NaN value.\n",
        "\n",
        "If you intialize a dataframe with indices and columns but no values, all values will be filled with NaN by default."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vfgse7I1xkSq"
      },
      "outputs": [],
      "source": [
        "z = pd.DataFrame(columns=[1, 2, 3, 4], index=[\"a\", \"b\", \"c\", \"d\"])\n",
        "print(z)\n",
        "\n",
        "printline(1)\n",
        "z.loc[\"b\",] = [5, 6, 7, 8]\n",
        "z.loc[\"c\",] = [5, 6, 7, 8]\n",
        "z.loc[:, 2] = [5, 6, 7, 8]\n",
        "z.loc[:, 3] = [5, 6, 7, 8]\n",
        "print(z)\n",
        "\n",
        "printline(2)\n",
        "a = z.copy(deep=True)\n",
        "a = a.dropna(axis=0)\n",
        "print(a)\n",
        "a = z.copy(deep=True)\n",
        "a = a.dropna(axis=1)\n",
        "print(a)\n",
        "\n",
        "printline(3)\n",
        "a = z.copy(deep=True)\n",
        "z = z.fillna(0)\n",
        "z = a.copy(deep=True)\n",
        "x = pd.Series([1, 2, 3, 4], index=[1, 5, 6, 7])\n",
        "z.fillna(x, inplace=True, axis=0)\n",
        "print(z)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MYiflTpvzIfA"
      },
      "source": [
        "# Example with dataset\n",
        "\n",
        "### Dataset explanation\n",
        "\n",
        "Next time! But you can take an initial look at the dataset here:\n",
        "\n",
        "https://www.kaggle.com/code/headsortails/wiki-traffic-forecast-exploration-wtf-eda\n",
        "\n",
        "### Workshop itenerary\n",
        "\n",
        "- dataset exploration and preprocessing with pandas and numpy, dataset plotting and visualization with matplotlib (workshop 2)\n",
        "- time series forecasting- 3 different methods using scipy, scikit-learn, and tensorflow (workshop 3)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.-1.-1"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
