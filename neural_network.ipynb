{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is a Neural Network?\n",
    "\n",
    "Neural networks are the overarching idea behind deep learning. By adjusting a set of weights and biases to fit itself to a dataset, neural networks are extremely versatile and can find patterns in many different types of data. Neural networks can also be built to specification, with different types networks and fine-tuning built for use cases such as image classification, time series analysis, and more.\n",
    "\n",
    "## Parts of a neural network\n",
    "\n",
    "Often when people try to explain a neural network, they show this image:\n",
    "\n",
    "[conventional digram of neural network]\n",
    "\n",
    "However, this diagram does not really make mathematical sense (nor does it make much sense from a programming perspective either). Thus, we shall begin with this diagram:\n",
    "\n",
    "``` \n",
    "           f_1(X)      f_2(X)             f_N(X)\n",
    "          +------+    +------+           +------+    \n",
    "input     |      |    |      |           |      |  output  \n",
    "--------> |      | -> |      | -> ... -> |      | --------> prediction \n",
    "          |      |    |      |           |      | \n",
    "          +------+    +------+           +------+    \n",
    "```\n",
    "\n",
    "The diagram shows that at its core, a neural network is just a composition of functions. These functions typically have the form \n",
    "\n",
    "$\\overrightarrow{y} = f_i(\\overrightarrow{x}; \\theta_1, ..., \\theta_n; h_1, ..., h_m)$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $\\overrightarrow{x}$: input vector of values\n",
    "- $\\overrightarrow{y}$: output vector of values\n",
    "- $\\theta_i$: trainable parameter (i.e., weight or bias)\n",
    "- $h_i$: hyperparameter (non-trainable parameter which affects the behaviour of the neural network)\n",
    "- $n \\geq{0}, m \\geq{0}$\n",
    "\n",
    "This is the bare essentials of a neural network. We are, however, missing some other essential parts which actually allow the neural network to actually get better at making predictions. Now we can refine this diagram a bit without loss of generality:\n",
    "\n",
    "``` \n",
    "           f_1(X)      f_2(X)             f_N(X)\n",
    "          +------+    +------+           +------+  output y \n",
    "input     |      | -> |      | -> ... -> |      | ---------->        comparison \n",
    "--------> |      |    |      |           |      |                vs. expected output\n",
    "          |      | <- |      | <- ... <- |      | <----------         E(y, y')\n",
    "          +------+    +------+           +------+   error O\n",
    "           b_1(O)      b_2(O)             b_N(O) \n",
    "```\n",
    "\n",
    "We have now added a few functions which give a better picture of how the neural network works. Once we use the forward functions $f_i$ to get a prediction (this process is known as feed-forward or forward propagation), we compare it against our expected output. We can then get an error metric using this comparison, denoted by a function $E$. This error is then passed back through the neural network using the backwards functions $b_i$ (this process is known as back propagation) to update the trainable parameters.\n",
    "\n",
    "We now have all the components of a neural network. But this is all very abstract. How do we actually define the functions $f_i$, $b_i$, and $R$? That is usecase-specific. In fact, we can build neural networks as we wish. We refer to each function $f_i$ as a layer of the neural network. Each layer has a corresponding backpropagation function $b_i$ which is defined based on the forward propagation function. With these definitions, we can now begin to describe different classes of neural network.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN/FNN\n",
    "\n",
    "### Introduction\n",
    "\n",
    "The Artificial Neural Network (ANN), also known as the feed-forward neural network (FNN), is the simplest type of neural network. It is also the one pictured in a conventional diagram like this one:\n",
    "\n",
    "[conventional diagram of neural network]\n",
    "\n",
    "An ANN is comprised of one or more layers, where each layer is comprised of one or more nodes, or neurons. Each neuron has a set of weights and biases, and produces an output (essentially a prediction) based on its weights and biases. Layers have the following form: \n",
    "\n",
    "$f_i(\\overrightarrow{x})$ = [$\\sigma(\\overrightarrow{x} \\cdot \\overrightarrow{w_j} + b_j)$ for each node $j$ in layer $i$] $\\in \\mathbb{R}^m$\n",
    "\n",
    "Such that:\n",
    "\n",
    "- $\\overrightarrow{x}$: input vector of values\n",
    "- $\\overrightarrow{w}$: vector of trainable weights\n",
    "- $b$: trainable bias parameter\n",
    "- $\\sigma$: activation function which transforms the final value\n",
    "- $\\overrightarrow{x}, \\overrightarrow{w} \\in \\mathbb{R}^n$ where n is the input size\n",
    "- output is a vector in $\\mathbb{R}^m$\n",
    "\n",
    "The input to $f_i$ is the result of $f_{i-1}$, that is, the output of all nodes from the previous layer. The first layer, $f_1$, is referred to as the input layer, while the last layer, $f_{N}$, is the output layer. All other layers are are referred to as hidden layers of the ANN.\n",
    "\n",
    "The layers of the neural network are **densely** connected- that is, each neuron from a layer receives input from **all** neurons in the layer before it, and propagates its output to **all** neurons in the layer after it. The following diagrams summarize the neuron and ANN architecture:\n",
    "\n",
    "[diagram of node]\n",
    "\n",
    "[detailed diagram of ANN]\n",
    "\n",
    "### Specifics\n",
    "\n",
    "So with that simple overview, we are ready to explain how an ANN actually works. This is the most important neural network to understand as all others are essentially variations on this one. \n",
    "\n",
    "When given a dataset, "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
